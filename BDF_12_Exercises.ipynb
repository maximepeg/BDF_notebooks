{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maximepeg/BDF_notebooks/blob/main/BDF_12_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL0HHBxQa1Hc"
      },
      "source": [
        "#00 - Configuration of Apache Spark on Collaboratory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcWXhOxia5yZ"
      },
      "source": [
        "###Installing Java, Spark, and Findspark\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This code installs Apache Spark 3.0.1, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsAfQ0CrgnWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae11219-bf21-4fc5-c323-dc6b96b48248"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget  http://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz  \n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz  \n",
        "!rm spark-3.3.1-bin-hadoop3.tgz    \n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,377 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [982 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,126 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,436 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,909 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,284 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,003 kB]\n",
            "Fetched 13.5 MB in 8s (1,727 kB/s)\n",
            "Reading package lists... Done\n",
            "--2023-01-22 20:05:29--  http://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
            "Resolving apache.osuosl.org (apache.osuosl.org)... 140.211.166.134, 64.50.236.52, 64.50.233.100, ...\n",
            "Connecting to apache.osuosl.org (apache.osuosl.org)|140.211.166.134|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299350810 (285M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.3.1-bin-had 100%[===================>] 285.48M  54.3MB/s    in 24s     \n",
            "\n",
            "2023-01-22 20:05:54 (11.8 MB/s) - ‘spark-3.3.1-bin-hadoop3.tgz’ saved [299350810/299350810]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urlhmQ_ra_ba"
      },
      "source": [
        "### Set Environment Variables\n",
        "Set the locations where Spark and Java are installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiOoj3rUgnVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682fa382-5c04-41d2-ab52-931b42d5a096"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark/\"\n",
        "os.environ[\"DRIVE_DATA\"] = \"/content/gdrive/My Drive/Enseignement/2022-2023/ING3/HPDA/BigDataFrameworks/data/\"\n",
        "\n",
        "!rm /content/spark\n",
        "!ln -s /content/spark-3.3.1-bin-hadoop3 /content/spark\n",
        "!export SPARK_HOME=/content/spark\n",
        "!export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n",
        "!echo $SPARK_HOME\n",
        "!env |grep  \"DRIVE_DATA\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/spark': No such file or directory\n",
            "/content/spark/\n",
            "DRIVE_DATA=/content/gdrive/My Drive/Enseignement/2022-2023/ING3/HPDA/BigDataFrameworks/data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2URH7tCHbDqf"
      },
      "source": [
        "### Start a SparkSession\n",
        "This will start a local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8JD51WVauRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fa3ac6-4024-449a-cef8-ccba46dfabe7"
      },
      "source": [
        "!python -V\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Example: shows the PySpark version\n",
        "print(\"PySpark version {0}\".format(sc.version))\n",
        "\n",
        "# Example: parallelise an array and show the 2 first elements\n",
        "sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n",
            "PySpark version 3.3.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar81vEOHauP2"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# We create a SparkSession object (or we retrieve it if it is already created)\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"My application\") \\\n",
        ".config(\"spark.some.config.option\", \"some-value\") \\\n",
        ".master(\"local[4]\") \\\n",
        ".getOrCreate()\n",
        "# We get the SparkContext\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBMAZitVauMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36d404e-4f20-4802-ad22-2535a60cb8aa"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jajoV8LDbTCe"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 12 - Exercises. Final assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4qzjHXyxcn"
      },
      "source": [
        "## Exercise 12.1\n",
        "\n",
        "Let us extract information from the cite75_99.txt and apat63_99.txt files. Write a script that performs the following operations:\n",
        "\n",
        "1. From the cite75_99.txt file, obtain the number of citations received by each patent. You must produce a DataFrame with the following format:\n",
        "\n",
        "| PatentNum | ncitations |\n",
        "|-----------|------------|\n",
        "| 3060453   |    3       |\n",
        "| 3390168   |    6       |\n",
        "| 3626542   |   18       | \n",
        "| 3611507   |    5       |\n",
        "| 3000113   |    4       |\n",
        "\n",
        "\n",
        "2. From the apat63_99.txt file, create a DataFrame to show the patent number, its country and the patent year, discarding the rest of fields in the file. The DataFrame produced must have the following format:\n",
        "\n",
        "|PatentNum |country|Year |\n",
        "|----------|-------|-----|\n",
        "| 3070801  | BE    | 1963| \n",
        "| 3070802  | US    | 1963| \n",
        "| 3070803  | US    | 1963| \n",
        "| 3070804  | US    | 1963| \n",
        "| 3070805  | US    | 1963|\n",
        "\n",
        " \n",
        "**Requirements**\n",
        "\n",
        " - Both DataFrames must be stored in Parquet format with gzip compression. Check the number of partitions of each DataFrame and the number of files gererated.\n",
        "\n",
        " - It is **strongly advised** to copy the files from your Drive to a temporal directory in the notebook virtual machine and unzip them there. This will reduce the execution times. See the cell below:\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV_M6xMlB9hP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d872a44f-23b3-47e2-f775-bfac47691a7a"
      },
      "source": [
        "!mkdir /tmp/data/\n",
        "!cp \"$DRIVE_DATA\"apat63_99.txt.tar.bz2 \"$DRIVE_DATA\"cite75_99.txt.tar.bz2 /tmp/data\n",
        "%cd /tmp/data\n",
        "!ls\n",
        "!tar -jxf apat63_99.txt.tar.bz2\n",
        "!tar -jxf cite75_99.txt.tar.bz2\n",
        "#!rm /tmp/data/*.tar.bz2\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/tmp/data/’: File exists\n",
            "/tmp/data\n",
            "apat63_99.txt  apat63_99.txt.tar.bz2  cite75_99.txt  cite75_99.txt.tar.bz2\n",
            "apat63_99.txt  apat63_99.txt.tar.bz2  cite75_99.txt  cite75_99.txt.tar.bz2\n",
            "/tmp/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.read.option(\"header\",True).csv(\"/tmp/data/\" + \"apat63_99.txt\")\n",
        "df = spark.read.option(\"header\",True).csv(os.environ[\"DRIVE_DATA\"] + \"cite75_99.txt\")\n"
      ],
      "metadata": {
        "id": "IXZWKDzfUESp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.show(10))\n",
        "print(df.show(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAGWXHPJIbhM",
        "outputId": "b2566aae-fb5f-44ee-a249-7ffc0bff886d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
            "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
            "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
            "|3070801| 1963| 1096|   null|     BE|   null|    null|      1|  null|   269|  6|    69| null|       1|    null|      0|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070802| 1963| 1096|   null|     US|     TX|    null|      1|  null|     2|  6|    63| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070803| 1963| 1096|   null|     US|     IL|    null|      1|  null|     2|  6|    63| null|       9|    null| 0.3704|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070804| 1963| 1096|   null|     US|     OH|    null|      1|  null|     2|  6|    63| null|       3|    null| 0.6667|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070805| 1963| 1096|   null|     US|     CA|    null|      1|  null|     2|  6|    63| null|       1|    null|      0|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070806| 1963| 1096|   null|     US|     PA|    null|      1|  null|     2|  6|    63| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070807| 1963| 1096|   null|     US|     OH|    null|      1|  null|   623|  3|    39| null|       3|    null| 0.4444|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070808| 1963| 1096|   null|     US|     IA|    null|      1|  null|   623|  3|    39| null|       4|    null|  0.375|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070809| 1963| 1096|   null|     US|     AZ|    null|      1|  null|     4|  6|    65| null|       0|    null|   null|    null|    null|    null|    null|    null|    null|    null|\n",
            "|3070810| 1963| 1096|   null|     US|     IL|    null|      1|  null|     4|  6|    65| null|       3|    null| 0.4444|    null|    null|    null|    null|    null|    null|    null|\n",
            "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
            "only showing top 10 rows\n",
            "\n",
            "None\n",
            "+-------+-------+\n",
            "| CITING|  CITED|\n",
            "+-------+-------+\n",
            "|3858241| 956203|\n",
            "|3858241|1324234|\n",
            "|3858241|3398406|\n",
            "|3858241|3557384|\n",
            "|3858241|3634889|\n",
            "|3858242|1515701|\n",
            "|3858242|3319261|\n",
            "|3858242|3668705|\n",
            "|3858242|3707004|\n",
            "|3858243|2949611|\n",
            "+-------+-------+\n",
            "only showing top 10 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "citation = df.groupBy(\"CITING\").count().withColumnRenamed(\"count\", \"ncitations\")\n",
        "citation.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4C7SNpwZsWO",
        "outputId": "08f03ff1-cc10-46bc-e65f-cfe4209b5f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "| CITING|ncitations|\n",
            "+-------+----------+\n",
            "|3858333|         3|\n",
            "|3858342|         5|\n",
            "|3858485|         4|\n",
            "|3858770|         4|\n",
            "|3858812|         4|\n",
            "|3859258|         3|\n",
            "|3859358|         2|\n",
            "|3859718|         3|\n",
            "|3859739|         5|\n",
            "|3859806|         5|\n",
            "+-------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "citation.write.mode('overwrite').parquet(\"/tmp/data/citations.parquet\")\n",
        "citation.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61XlmJE2Ktwi",
        "outputId": "74582305-9c24-4fef-d1b9-f525541269ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patent_info = df2.select('PATENT', 'COUNTRY','GYEAR')\n",
        "patent_info.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFio3B8cXzBZ",
        "outputId": "4b700f25-4b05-46da-f064-0534586e3b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+\n",
            "| PATENT|COUNTRY|GYEAR|\n",
            "+-------+-------+-----+\n",
            "|3070801|     BE| 1963|\n",
            "|3070802|     US| 1963|\n",
            "|3070803|     US| 1963|\n",
            "|3070804|     US| 1963|\n",
            "|3070805|     US| 1963|\n",
            "|3070806|     US| 1963|\n",
            "|3070807|     US| 1963|\n",
            "|3070808|     US| 1963|\n",
            "|3070809|     US| 1963|\n",
            "|3070810|     US| 1963|\n",
            "+-------+-------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patent_info.write.mode('overwrite').parquet(\"/tmp/data/patent.parquet\")\n",
        "patent_info.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEm3kdsVL_U6",
        "outputId": "eb78506e-6bb3-4770-a995-a6f7988375f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/data/*.parquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqBOTfRHMI9p",
        "outputId": "358c539e-5349-4ecc-891e-9936e91f0f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/data/citations.parquet:\n",
            "part-00000-345a153d-4518-40eb-98d1-991b52c27260-c000.snappy.parquet  _SUCCESS\n",
            "part-00001-345a153d-4518-40eb-98d1-991b52c27260-c000.snappy.parquet\n",
            "\n",
            "/tmp/data/patent.parquet:\n",
            "part-00000-3b0bc1a3-63a4-47dc-9fa7-d4e0c577d2ca-c000.snappy.parquet  _SUCCESS\n",
            "part-00001-3b0bc1a3-63a4-47dc-9fa7-d4e0c577d2ca-c000.snappy.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF1_LXZEnzMn"
      },
      "source": [
        "## Exercise 12.2\n",
        "\n",
        "Write a code that, from the Parquet files created in the previous exercise, obtains for each country and for each year: the total number of patents, the total number of citations from those patents, the average number of citations and the maximum number of citations. Compute only those values in which there are any values in both files (*inner join*). In addition, each country must show its whole name, obtained from the *country_codes.txt* file. The final DataFrame must look like this one:\n",
        "\n",
        "\n",
        "|Country            |Year|PatentsNum |TotalCitations|AvgCitations      |MaxCitations|\n",
        "|-------------------|----|-----------|--------------|------------------|------------|\n",
        "|Algeria            |1963|2          |7             |3.5               |4           |\n",
        "|Algeria            |1968|1          |2             |2.0               |2           |\n",
        "|Algeria            |1970|1          |2             |2.0               |2           |\n",
        "|Algeria            |1972|1          |1             |1.0               |1           |\n",
        "|Algeria            |1977|1          |2             |2.0               |2           |\n",
        "|Andorra            |1987|1          |3             |3.0               |3           |\n",
        "|Andorra            |1993|1          |1             |1.0               |1           |\n",
        "|Andorra            |1998|1          |1             |1.0               |1           |\n",
        "|Antigua and Barbuda|1978|1          |6             |6.0               |6           |\n",
        "|Antigua and Barbuda|1979|1          |14            |14.0              |14          |\n",
        "|Antigua and Barbuda|1991|1          |8             |8.0               |8           |\n",
        "|Antigua and Barbuda|1994|1          |19            |19.0              |19          |\n",
        "|Antigua and Barbuda|1995|2          |12            |6.0               |11          |\n",
        "|Antigua and Barbuda|1996|2          |3             |1.5               |2           |\n",
        "|Argentina          |1963|14         |35            |2.5               |7           |\n",
        "|Argentina          |1964|20         |60            |3.0               |8           |\n",
        "|Argentina          |1965|10         |35            |3.5               |10          |\n",
        "|Argentina          |1966|16         |44            |2.75              |9           |\n",
        "|Argentina          |1967|13         |60            |4.615384615384615 |14          |\n",
        "\n",
        "**Requirements**\n",
        "\n",
        "- The output DataFrame must be saved in a single CSV file, with a header and without any compression.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"$DRIVE_DATA\"country_codes.txt /tmp/data/country_codes.txt\n",
        "!ls /tmp/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q64mZZUDXO3r",
        "outputId": "0e171c2e-81c6-4037-c376-08c31280f677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apat63_99.txt\t       citations.parquet  cite75_99.txt.tar.bz2  patent.parquet\n",
            "apat63_99.txt.tar.bz2  cite75_99.txt\t  country_codes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countries = spark.read.options(header=False, delimiter=\"\\t\").csv(\"/tmp/data/country_codes.txt\").withColumnRenamed(\"_c0\", \"COUNTRY_CODE\").withColumnRenamed(\"_c1\", \"COUNTRY\")\n",
        "cit = spark.read.parquet(\"/tmp/data/citations.parquet\").withColumnRenamed(\"CITING\", \"PATENT\")\n",
        "pat = spark.read.parquet(\"/tmp/data/patent.parquet\").withColumnRenamed(\"COUNTRY\", \"COUNTRY_CODE\")\n",
        "print(pat.show(5))\n",
        "print(cit.show(5))\n",
        "print(countries.show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKYTFLyQNaqy",
        "outputId": "02723e42-1739-499e-b661-38f6ff6e8b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-----+\n",
            "| PATENT|COUNTRY_CODE|GYEAR|\n",
            "+-------+------------+-----+\n",
            "|3070801|          BE| 1963|\n",
            "|3070802|          US| 1963|\n",
            "|3070803|          US| 1963|\n",
            "|3070804|          US| 1963|\n",
            "|3070805|          US| 1963|\n",
            "+-------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "+-------+----------+\n",
            "| PATENT|ncitations|\n",
            "+-------+----------+\n",
            "|3858333|         3|\n",
            "|3858342|         5|\n",
            "|3858485|         4|\n",
            "|3858770|         4|\n",
            "|3858812|         4|\n",
            "+-------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "+------------+--------------+\n",
            "|COUNTRY_CODE|       COUNTRY|\n",
            "+------------+--------------+\n",
            "|          AF|   Afghanistan|\n",
            "|          AX| Aland Islands|\n",
            "|          AL|       Albania|\n",
            "|          DZ|       Algeria|\n",
            "|          AS|American Samoa|\n",
            "+------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum,avg,max, count, countDistinct"
      ],
      "metadata": {
        "id": "iKpep1TzjqCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = cit.join(pat, on=\"PATENT\", how=\"inner\").join(countries, on=\"COUNTRY_CODE\", how=\"left\").withColumnRenamed(\"GYEAR\",\"YEAR\")\n",
        "\n",
        "full_patent_stats =data_df.groupBy(\"COUNTRY\", \"YEAR\").agg(countDistinct(\"PATENT\").alias(\"PatentNums\"), \n",
        "                                                          sum(\"ncitations\").alias(\"TotalCitations\"), \n",
        "                                                          avg(\"ncitations\").alias(\"AvgCitations\"),\n",
        "                                                          max(\"ncitations\").alias(\"MaxCitations\"))\n",
        "full_patent_stats.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mylfEiMDOVP_",
        "outputId": "49a0f3ea-0771-42a2-d66d-ee3e19e5868d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+----------+--------------+------------------+------------+\n",
            "|             COUNTRY|YEAR|PatentNums|TotalCitations|      AvgCitations|MaxCitations|\n",
            "+--------------------+----+----------+--------------+------------------+------------+\n",
            "|            Colombia|1978|         7|            24|3.4285714285714284|           7|\n",
            "|           Australia|1979|       207|          1075| 5.193236714975845|          15|\n",
            "|Serbia and Monten...|1980|        13|            73| 5.615384615384615|          13|\n",
            "|              Canada|1980|      1055|          6020| 5.706161137440758|          32|\n",
            "|Czechoslovakia (f...|1980|        53|           253| 4.773584905660377|          13|\n",
            "+--------------------+----+----------+--------------+------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT3WU-1IwOPD"
      },
      "source": [
        "## Exercise 12.3\n",
        "\n",
        "From the apat63_99.txt file, obtain the number of patents per country and year **using RDDs** (do not use DataFrames). The resulting RDD must be a key/value RDD in which the key is a country and the value a list of tuples. Each tuple will be composed of a year and the number of patents of the country during that year. In addition, the resulting RDD must be sorted by  the country code and, for each country, values must be sorted by year.\n",
        "\n",
        "Example of output key/value entry:\n",
        "\n",
        "    (u'PA', [(u'1963', 2), (u'1964', 2), (u'1965', 1), (u'1966', 1), (u'1970', 1), (u'1971', 1), (u'1972', 6), (u'1974', 3), (u'1975', 5), (u'1976', 3), (u'1977', 2), (u'1978', 2), (u'1980', 2), (u'1982', 1), (u'1983', 1), (u'1985', 2), (u'1986', 1), (u'1987', 2), (u'1988', 1), (u'1990', 1), (u'1991', 2), (u'1993', 1), (u'1995', 1), (u'1996', 1), (u'1999', 1)])\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "- You must remove the double quotation marks from the country code.\n",
        "- Use 8 partitions to read the apat63_99.txt.bz2 file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YLKS0ozUvU4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tupled_rdd = spark.sparkContext.textFile(\"/tmp/data/apat63_99.txt\", minPartitions=8).map(lambda x: x.split(\",\")).map(lambda x:((x[4].replace('\"',''), x[1]), x[0] )).groupByKey().mapValues(len).map(lambda x: (x[0][0], (x[0][1],x[1]))).groupByKey().mapValues(list).sortBy(lambda x: (x[0], x[1][0]))\n",
        "\n",
        "tupled_rdd.take(5)"
      ],
      "metadata": {
        "id": "83vcfcsFOT9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13f7b1d-8127-4ac4-9176-66106e5778d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AD', [('1999', 1), ('1995', 1), ('1998', 2), ('1993', 1), ('1987', 1)]),\n",
              " ('AE',\n",
              "  [('1984', 2),\n",
              "   ('1996', 1),\n",
              "   ('1994', 1),\n",
              "   ('1987', 1),\n",
              "   ('1989', 2),\n",
              "   ('1992', 1),\n",
              "   ('1991', 2),\n",
              "   ('1985', 2),\n",
              "   ('1999', 3),\n",
              "   ('1990', 1),\n",
              "   ('1998', 1),\n",
              "   ('1993', 1)]),\n",
              " ('AG',\n",
              "  [('1995', 2),\n",
              "   ('1999', 1),\n",
              "   ('1991', 1),\n",
              "   ('1979', 1),\n",
              "   ('1994', 1),\n",
              "   ('1996', 2),\n",
              "   ('1978', 1)]),\n",
              " ('AI', [('1998', 1)]),\n",
              " ('AL', [('1999', 1)])]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0LiWoc4VQdh"
      },
      "source": [
        "## Exercise 12.4\n",
        "\n",
        "From the Parquet files created in Exercise 12.1, create a DataFrame that gives the patent or patents with the higher number of citations per country and year, as well as the average of the number of citations per country and year, and the difference between the maximum and the average values. The resulting DataFrame should look like this:\n",
        "\n",
        "\n",
        "|Country|Year|PatentNum|max  |average       |diff              |\n",
        "|-------|----|---------|-----|--------------|------------------|\n",
        "|AD     |1987|4688621  |3    |3.0           |0.0               |\n",
        "|AD     |1993|5193231  |1    |1.0           |0.0               |\n",
        "|AD     |1998|5765303  |1    |1.0           |0.0               |\n",
        "|AE     |1984|4482959  |5    |5.0           |0.0               |\n",
        "|AE     |1985|4554981  |14   |14.0          |0.0               |\n",
        "|AE     |1987|4663181  |3    |3.0           |0.0               |\n",
        "|AE     |1989|4805221  |7    |5.0           |2.0               |\n",
        "|AE     |1990|4909321  |2    |2.0           |0.0               |\n",
        "|AE     |1991|5004552  |3    |2.0           |1.0               |\n",
        "|AE     |1992|5104556  |4    |4.0           |0.0               |\n",
        "|AE     |1993|5181569  |8    |8.0           |0.0               |\n",
        "|AE     |1996|5580125  |1    |1.0           |0.0               |\n",
        "|AG     |1978|4126850  |6    |6.0           |0.0               |\n",
        "|AG     |1979|4172981  |14   |14.0          |0.0               |\n",
        "|AG     |1991|5013035  |8    |8.0           |0.0               |\n",
        "|AG     |1994|5345071  |19   |19.0          |0.0               |\n",
        "|AG     |1995|5457307  |11   |6.0           |5.0               |\n",
        "|AG     |1996|5525786  |2    |1.5           |0.5               |\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "- The DataFrame must be sorted by country code and year.\n",
        "- Do **NOT** replace the country code by its whole name.\n",
        "- The output must be saved as a single CSV file, with a header and without any compression.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cit = spark.read.parquet(\"/tmp/data/citations.parquet\").withColumnRenamed(\"CITING\", \"PATENT\")\n",
        "pat = spark.read.parquet(\"/tmp/data/patent.parquet\").withColumnRenamed(\"COUNTRY\", \"COUNTRY_CODE\")\n",
        "print(cit.show(5))\n",
        "print(pat.show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBimSd6S00RM",
        "outputId": "78f7b74f-4ae8-463a-de29-7383d079fd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "| PATENT|ncitations|\n",
            "+-------+----------+\n",
            "|3858333|         3|\n",
            "|3858342|         5|\n",
            "|3858485|         4|\n",
            "|3858770|         4|\n",
            "|3858812|         4|\n",
            "+-------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "+-------+------------+-----+\n",
            "| PATENT|COUNTRY_CODE|GYEAR|\n",
            "+-------+------------+-----+\n",
            "|3070801|          BE| 1963|\n",
            "|3070802|          US| 1963|\n",
            "|3070803|          US| 1963|\n",
            "|3070804|          US| 1963|\n",
            "|3070805|          US| 1963|\n",
            "+-------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max_by, abs\n",
        "df_diff= cit.join(pat, on=\"PATENT\", how=\"inner\").groupBy(\"COUNTRY_CODE\", \"GYEAR\").agg(max_by(\"PATENT\", \"ncitations\").alias(\"patent\"), \n",
        "                                                                                      max(\"ncitations\").alias(\"max\"),\n",
        "                                                                                      avg(\"ncitations\").alias(\"avg\"),\n",
        "                                                                                      abs(max(\"ncitations\") - avg(\"ncitations\")).alias(\"diff\"))\n",
        "df_diff.show(10)\n",
        "df_diff.coalesce(1).write.csv(\"/tmp/data/patent_data_with_diff.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcZsGWBt1Pcx",
        "outputId": "c405c121-fa7d-4f06-c82a-3d97399132f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+-------+---+----+----+\n",
            "|COUNTRY_CODE|GYEAR| patent|max| avg|diff|\n",
            "+------------+-----+-------+---+----+----+\n",
            "|          AD| 1987|4688621|  9| 9.0| 0.0|\n",
            "|          AD| 1993|5193231|  2| 2.0| 0.0|\n",
            "|          AD| 1995|5478082|  8| 8.0| 0.0|\n",
            "|          AD| 1998|5765303| 11| 7.0| 4.0|\n",
            "|          AD| 1999|5894770|  4| 4.0| 0.0|\n",
            "|          AE| 1984|4482959|  6| 5.5| 0.5|\n",
            "|          AE| 1985|4532995| 11|10.5| 0.5|\n",
            "|          AE| 1987|4663181|  4| 4.0| 0.0|\n",
            "|          AE| 1989|4805221| 13|12.0| 1.0|\n",
            "|          AE| 1990|4909321| 17|17.0| 0.0|\n",
            "+------------+-----+-------+---+----+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tnSZ8OpG35y7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektPyLWzaImT"
      },
      "source": [
        "!## Exercise 12.5\n",
        "\n",
        "From the Parquet file with the (PatentNum,Country,Year) information from Exercise 12.1, create a DataFrame that shows the number of patents associated to each country per decade (understanding as a *decade* the years from 0 to 9; e.g. from 1970 to 1979). In addition, the DataFrame must show the increase or decrease of the number of patents per country and decade with respect to the previous decade. The resulting DataFrame must look like this:\n",
        "\n",
        "|Country|Decade|PatentsNum|Diff|\n",
        "|-------|------|----------|----|\n",
        "|AD     |1980  |1         |0   |\n",
        "|AD     |1990  |5         |4   |\n",
        "|AE     |1980  |7         |0   |\n",
        "|AE     |1990  |11        |4   |\n",
        "|AG     |1970  |2         |0   |\n",
        "|AG     |1990  |7         |5   |\n",
        "|AI     |1990  |1         |0   |\n",
        "|AL     |1990  |1         |0   |\n",
        "|AM     |1990  |2         |0   |\n",
        "|AN     |1970  |1         |0   |\n",
        "|AN     |1980  |2         |1   |\n",
        "|AN     |1990  |5         |3   |\n",
        "|AR     |1960  |135       |0   |\n",
        "|AR     |1970  |239       |104 |\n",
        "|AR     |1980  |184       |-55 |\n",
        "|AR     |1990  |292       |108 |\n",
        "\n",
        "**Requirements**\n",
        "\n",
        "- The DataFrame must be sorted by country code and year.\n",
        "- Do **NOT** replace the country code by its whole name.\n",
        "- The output must be saved as a single CSV file, with a header and without any compression."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cit = spark.read.parquet(\"/tmp/data/citations.parquet\").withColumnRenamed(\"CITING\", \"PATENT\")\n",
        "pat = spark.read.parquet(\"/tmp/data/patent.parquet\").withColumnRenamed(\"COUNTRY\", \"COUNTRY_CODE\")\n",
        "print(cit.show(5))\n",
        "print(pat.show(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmZe1abu6IvF",
        "outputId": "7951c797-bd3e-4af0-9c75-42a6dfff2195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "| PATENT|ncitations|\n",
            "+-------+----------+\n",
            "|3858333|         3|\n",
            "|3858342|         5|\n",
            "|3858485|         4|\n",
            "|3858770|         4|\n",
            "|3858812|         4|\n",
            "+-------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "+-------+------------+-----+\n",
            "| PATENT|COUNTRY_CODE|GYEAR|\n",
            "+-------+------------+-----+\n",
            "|3070801|          BE| 1963|\n",
            "|3070802|          US| 1963|\n",
            "|3070803|          US| 1963|\n",
            "|3070804|          US| 1963|\n",
            "|3070805|          US| 1963|\n",
            "+-------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import round, lag\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "w = Window.partitionBy(\"COUNTRY_CODE\").orderBy(\"DECADE\")\n",
        "df_lag = cit.join(pat, on=\"PATENT\", how=\"inner\").withColumn(\"DECADE\", round(\"GYEAR\", -1)-10).groupBy(\"COUNTRY_CODE\", \"DECADE\").agg(sum(\"ncitations\").alias(\"patentNums\"))\n",
        "df_lag = df_lag.withColumn(\"lag\", lag(\"patentNums\", 0).over(w) - lag(\"patentNums\", 1).over(w)).fillna(0)\n",
        "df_lag.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvjxrJBN6Jdz",
        "outputId": "3b955321-bfe0-49ee-e979-b9bf458a8566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+----------+---+\n",
            "|COUNTRY_CODE|DECADE|patentNums|lag|\n",
            "+------------+------+----------+---+\n",
            "|          AD|1980.0|        11|  0|\n",
            "|          AD|1990.0|        26| 15|\n",
            "|          AE|1970.0|        11|  0|\n",
            "|          AE|1980.0|       115|104|\n",
            "|          AE|1990.0|        52|-63|\n",
            "|          AG|1970.0|        17|  0|\n",
            "|          AG|1980.0|        13| -4|\n",
            "|          AG|1990.0|        32| 19|\n",
            "|          AI|1990.0|        11|  0|\n",
            "|          AM|1990.0|        25|  0|\n",
            "+------------+------+----------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_lag.coalesce(1).write.csv(\"/tmp/data/patent_data_with_previous_year_comparison.csv\")\n"
      ],
      "metadata": {
        "id": "WVtyU0yg6ikI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4FRZ7e2-pKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}