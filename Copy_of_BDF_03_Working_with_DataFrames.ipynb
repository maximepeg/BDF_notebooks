{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maximepeg/BDF_notebooks/blob/main/Copy_of_BDF_03_Working_with_DataFrames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-h_wDcNlH_K"
      },
      "source": [
        "#00 - Configuration of Apache Spark on Collaboratory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvD4HBMi0ohY"
      },
      "source": [
        "###Installing Java, Spark, and Findspark\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This code installs Apache Spark 2.4.4, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsAfQ0CrgnWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3738c4-814c-4401-abd9-ebc3387f51d4"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget  http://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz  \n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz  \n",
        "!rm spark-3.3.1-bin-hadoop3.tgz    \n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,225 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,138 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,336 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,303 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,492 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.9 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,262 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,065 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,561 kB]\n",
            "Fetched 16.7 MB in 4s (3,917 kB/s)\n",
            "Reading package lists... Done\n",
            "--2022-11-17 13:35:12--  http://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
            "Resolving apache.osuosl.org (apache.osuosl.org)... 64.50.236.52, 64.50.233.100, 140.211.166.134, ...\n",
            "Connecting to apache.osuosl.org (apache.osuosl.org)|64.50.236.52|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299350810 (285M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.1-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.3.1-bin-had 100%[===================>] 285.48M  30.1MB/s    in 33s     \n",
            "\n",
            "2022-11-17 13:35:46 (8.54 MB/s) - ‘spark-3.3.1-bin-hadoop3.tgz’ saved [299350810/299350810]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Kjvk_h1AHl"
      },
      "source": [
        "### Set Environment Variables\n",
        "Set the locations where Spark and Java are installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiOoj3rUgnVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7725c1e9-7282-4462-e106-0eafe6e7f9e1"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark/\"\n",
        "os.environ[\"DRIVE_DATA\"] = \"/content/gdrive/My Drive/Enseignement/2022-2023/ING3/HPDA/BigDataFrameworks/data/\"\n",
        "\n",
        "!rm /content/spark\n",
        "!ln -s /content/spark-3.3.1-bin-hadoop3 /content/spark\n",
        "!export SPARK_HOME=/content/spark\n",
        "!export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n",
        "!echo $SPARK_HOME\n",
        "!env |grep  \"DRIVE_DATA\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spark/\n",
            "DRIVE_DATA=/content/gdrive/My Drive/Enseignement/2022-2023/ING3/HPDA/BigDataFrameworks/data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwU28K5f1H3P"
      },
      "source": [
        "### Start a SparkSession\n",
        "This will start a local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-4asPkCgnVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be054274-24c4-45ac-860a-825fa554b4c9"
      },
      "source": [
        "!python -V\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Example: shows the PySpark version\n",
        "print(\"PySpark version {0}\".format(sc.version))\n",
        "\n",
        "# Example: parallelise an array and show the 2 first elements\n",
        "sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n",
            "PySpark version 3.3.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pth1GUUrgnUW"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# We create a SparkSession object (or we retrieve it if it is already created)\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"My application\") \\\n",
        ".config(\"spark.some.config.option\", \"some-value\") \\\n",
        ".master(\"local[4]\") \\\n",
        ".getOrCreate()\n",
        "# We get the SparkContext\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tfoycrngnSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a863338-65c5-489b-e1a6-436b9418b944"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkKGBZRvEwZL"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 03 - Working with DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcr9KTJbJI_4"
      },
      "source": [
        "## Introduction to DataFrames\n",
        "We will see:\n",
        "\n",
        "  - How to create a DataFrame\n",
        "  - Basic operations on DataFrames\n",
        "      - Show rows\n",
        "      - Select columns\n",
        "      - Rename, add and delete columns\n",
        "      - Delete null values and duplicated rows\n",
        "      - Replace values\n",
        "  - Save DataFrames in different formats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu6TkZeNd5hz"
      },
      "source": [
        "## Creating DataFrames\n",
        "A DataFrame can be created in different ways:\n",
        "\n",
        "  - From a data sequence\n",
        "  - From Row-type objects \n",
        "  - From an RDD or a DataSet\n",
        "  - Reading data from a file\n",
        "      - Like in Hadoop, Spark supports different filesystems: local, HDFS, Amazon S3\n",
        "          - By and large, it supports any data source that can be read with Hadoop\n",
        "      - Spark can access different types of files: plain text, CSV, JSON, [Parquet](https://parquet.apache.org/), [ORC](https://orc.apache.org/), Sequence, etc\n",
        "        -   It also supports compressed files\n",
        "  - Accessing relational databases or noSQL databases\n",
        "    -   MySQL, Postgres, etc. using JDBC/ODBC\n",
        "    -  Hive, HBase, Cassandra, MongoDB, AWS Redshift, etc.\n",
        "    \n",
        "Some examples on how to create DataFrames below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDJ4UH8wfoO7"
      },
      "source": [
        "### From a sequence or a list of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCnbq2bgf5Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef7f31c-f743-4fc1-df77-fd12ae202965"
      },
      "source": [
        "from pyspark.sql.functions import col,expr\n",
        "# Creating a DataFrame from a range and adding two columns\n",
        "df = spark.range(1,7,2).toDF(\"n\")\n",
        "df.show()\n",
        "df.withColumn(\"n1\", col(\"n\")+1).withColumn(\"n2\", expr(\"2*n\")).show()\n",
        "# Note that in the call to 'expr' we can include SQL code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|  n|\n",
            "+---+\n",
            "|  1|\n",
            "|  3|\n",
            "|  5|\n",
            "+---+\n",
            "\n",
            "+---+---+---+\n",
            "|  n| n1| n2|\n",
            "+---+---+---+\n",
            "|  1|  2|  2|\n",
            "|  3|  4|  6|\n",
            "|  5|  6| 10|\n",
            "+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxcY86E-f9Ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84236c58-7636-4d90-8aeb-efbfae4042e3"
      },
      "source": [
        "# DataFrame from a list of tuples\n",
        "l = [(\"Eric\", 5.1, \"Pass\"),\\\n",
        "     (\"John\", 4.0, \"Fail\"),\\\n",
        "     (\"Manuel\", None, None)]\n",
        "dfMarks = spark.createDataFrame(l, schema=[\"Name\", \"mark\", \"result\"])\n",
        "dfMarks.show()\n",
        "dfMarks.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+\n",
            "|  Name|mark|result|\n",
            "+------+----+------+\n",
            "|  Eric| 5.1|  Pass|\n",
            "|  John| 4.0|  Fail|\n",
            "|Manuel|null|  null|\n",
            "+------+----+------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- mark: double (nullable = true)\n",
            " |-- result: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH7LS_dYgCmH"
      },
      "source": [
        "### Creating DataFrames with a schema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88zsnXygSlG"
      },
      "source": [
        "When creating a DataFrame, it is a good idea to specify its schema:\n",
        "\n",
        "  - The schema defines the names and data types of each column\n",
        "  - It uses an object of type ``StructType`` to define the name and type of the columns \n",
        "  - The data types used by Spark are defined in:\n",
        "      - For PySpark: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\n",
        "      - For Scala: https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.types.package\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uStMKrWmgcfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58308e49-683c-4fa5-dca8-54a26a4376d3"
      },
      "source": [
        "from pyspark.sql.types import StructField, StructType, FloatType, StringType\n",
        "from pyspark.sql import Row\n",
        "# Define the DataFrame schema\n",
        "schemaMarks = StructType([\n",
        "    StructField(\"Name\", StringType(), False),\n",
        "    StructField(\"mark\", FloatType(), True),\n",
        "    StructField(\"result\", StringType(), True)\n",
        "    ])\n",
        "    \n",
        "# Create the DataFrame from a list of Row objects\n",
        "rows = [Row(\"Eric\", 5.1, \"Pass\"),\\\n",
        "         Row(\"John\", 4.0, \"Fail\"),\\\n",
        "         Row(\"Manuel\", None, None)]\n",
        "\n",
        "dfMarks = spark.createDataFrame(rows, schema=schemaMarks)\n",
        "dfMarks.show()\n",
        "dfMarks.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+\n",
            "|  Name|mark|result|\n",
            "+------+----+------+\n",
            "|  Eric| 5.1|  Pass|\n",
            "|  John| 4.0|  Fail|\n",
            "|Manuel|null|  null|\n",
            "+------+----+------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = false)\n",
            " |-- mark: float (nullable = true)\n",
            " |-- result: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-C7Wg96gd5s"
      },
      "source": [
        "### Creating DataFrames from a text file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9bRWavNgk0U"
      },
      "source": [
        "Each file line is stored as a row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nxsEccsgqER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ff2f82-247f-4f9e-8539-fd965222443e"
      },
      "source": [
        "# Mount first the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dfQuijote = spark.read.text(os.environ[\"DRIVE_DATA\"] + \"/quijote.txt\")\n",
        "dfQuijote.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "+---------------------------------------------------------------------------+\n",
            "|value                                                                      |\n",
            "+---------------------------------------------------------------------------+\n",
            "|The Project Gutenberg EBook of Don Quijote, by Miguel de Cervantes Saavedra|\n",
            "|                                                                           |\n",
            "|This eBook is for the use of anyone anywhere at no cost and with           |\n",
            "|almost no restrictions whatsoever.  You may copy it, give it away or       |\n",
            "|re-use it under the terms of the Project Gutenberg License included        |\n",
            "|with this eBook or online at www.gutenberg.net                             |\n",
            "|                                                                           |\n",
            "|                                                                           |\n",
            "|Title: Don Quijote                                                         |\n",
            "|                                                                           |\n",
            "|Author: Miguel de Cervantes Saavedra                                       |\n",
            "|                                                                           |\n",
            "|Posting Date: April 27, 2010 [EBook #2000]                                 |\n",
            "|Release Date: December, 1999                                               |\n",
            "|                                                                           |\n",
            "|Language: Spanish                                                          |\n",
            "|                                                                           |\n",
            "|                                                                           |\n",
            "|*** START OF THIS PROJECT GUTENBERG EBOOK DON QUIJOTE ***                  |\n",
            "|                                                                           |\n",
            "+---------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbijvVbcgtw3"
      },
      "source": [
        "### Creating DataFrames from a CSV file (revisited)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDIe3EAEg4xo"
      },
      "source": [
        "As an example, we are going to use a file with questions and replies from Stack Exchange (https://stackexchange.com/) in Italian. \n",
        "It is a CVS file, with the following 13 fields:\n",
        "\n",
        "  0. ``nComs`` - Number of comments of the question of the reply\n",
        "  2. ``lastActivity`` - Date and hour of the last modification\n",
        "  3. ``userId`` - Owner's ID \n",
        "  4. ``body`` - Text of the question or reply\n",
        "  5. ``score`` - Score of the question or reply based on positive and negative votes\n",
        "  6. ``creationDate`` - Creation date and hour \n",
        "  6. ``numViewed`` - Number of times viewed (null if the question has never been viewed)\n",
        "  7. ``title`` - Question title (null if it is a reply)\n",
        "  8. ``tags`` - Tags assigned to the question (null if there are no tags assigned)\n",
        "  9. ``nAnswers`` - Number of replies related to the question (null if there are not any)\n",
        "  10. ``acceptedAnswerId`` - The ID of the accepted answer (null if the question has no accepted answer)\n",
        "  11. ``postType`` - Type of message: 1 question, 2 reply\n",
        "  12. ``id`` - Unique message identifier\n",
        "\n",
        "Fields are separated by the \"~\" symbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H07ygUKhL0p"
      },
      "source": [
        "#### a) Read the file and infer the schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Lzn1GMhXxz"
      },
      "source": [
        "dfSEInferred = spark.read.format(\"csv\")\\\n",
        "                    .option(\"mode\", \"FAILFAST\")\\\n",
        "                    .option(\"sep\", \"~\")\\\n",
        "                    .option(\"inferSchema\", \"true\")\\\n",
        "                    .option(\"header\", \"false\")\\\n",
        "                    .option(\"nullValue\", \"null\")\\\n",
        "                    .option(\"compression\", \"bzip2\")\\\n",
        "                    .load(os.environ[\"DRIVE_DATA\"] +\"italianPosts.csv.bz2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTjGjjNNhYUf"
      },
      "source": [
        "Some options:\n",
        "\n",
        "1. ``mode``: specifies what to do when it finds corrupted entries\n",
        "    - ``PERMISSIVE``: sets all fields to null when a corrupted entry is found (default value)\n",
        "    - ``DROPMALFORMED``: deletes the rows with corrupted entries \n",
        "    - ``FAILFAST``: returns an error when a corrupted entry is found\n",
        "2. ``sep``:  field delimiter (by default \",\")\n",
        "3. ``inferSchema``: whether column types must be inferred (by default \"false\")\n",
        "4. ``header``: if \"true\", the first line is taken as the header (by default \"false\")\n",
        "5. ``nullValue``: character or string thar represents a NULL in the file  (by default \"\")\n",
        "6. ``compression``: compression type (by default \"none\")\n",
        "  \n",
        "These options are similar for other types of files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1atd4MqhghB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685c3168-e486-4beb-bc01-0127ef9954a2"
      },
      "source": [
        "# Show 5 rows\n",
        "dfSEInferred.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+---+--------------------+---+--------------------+----+--------------------+--------------------+----+----+----+----+\n",
            "|_c0|                 _c1|_c2|                 _c3|_c4|                 _c5| _c6|                 _c7|                 _c8| _c9|_c10|_c11|_c12|\n",
            "+---+--------------------+---+--------------------+---+--------------------+----+--------------------+--------------------+----+----+----+----+\n",
            "|  4|2013-11-11 18:21:...| 17|&lt;p&gt;The infi...| 23|2013-11-10 19:37:...|null|                null|                null|null|null|   2|1165|\n",
            "|  5|2013-11-10 20:31:...| 12|&lt;p&gt;Come cre...|  1|2013-11-10 19:44:...|  61|Cosa sapreste dir...| &lt;word-choice&gt;|   1|null|   1|1166|\n",
            "|  2|2013-11-10 20:31:...| 17|&lt;p&gt;Il verbo...|  5|2013-11-10 19:58:...|null|                null|                null|null|null|   2|1167|\n",
            "|  1|2014-07-25 13:15:...|154|&lt;p&gt;As part ...| 11|2013-11-10 22:03:...| 187|Ironic constructi...|&lt;english-compa...|   4|1170|   1|1168|\n",
            "|  0|2013-11-10 22:15:...| 70|&lt;p&gt;&lt;em&g...|  3|2013-11-10 22:15:...|null|                null|                null|null|null|   2|1169|\n",
            "+---+--------------------+---+--------------------+---+--------------------+----+--------------------+--------------------+----+----+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjM7KCurhkRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6fbc9d-99d3-466c-a528-8dffa1234050"
      },
      "source": [
        "# Find out how the schema was inferred\n",
        "dfSEInferred.schema"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('_c0', IntegerType(), True), StructField('_c1', TimestampType(), True), StructField('_c2', IntegerType(), True), StructField('_c3', StringType(), True), StructField('_c4', IntegerType(), True), StructField('_c5', TimestampType(), True), StructField('_c6', IntegerType(), True), StructField('_c7', StringType(), True), StructField('_c8', StringType(), True), StructField('_c9', IntegerType(), True), StructField('_c10', IntegerType(), True), StructField('_c11', IntegerType(), True), StructField('_c12', IntegerType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Q9AQ4dhn5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9bc77fb-ae84-4e3c-c7cd-e5bcacf0e8ca"
      },
      "source": [
        "# Another way of getting the same result\n",
        "dfSEInferred.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- _c1: timestamp (nullable = true)\n",
            " |-- _c2: integer (nullable = true)\n",
            " |-- _c3: string (nullable = true)\n",
            " |-- _c4: integer (nullable = true)\n",
            " |-- _c5: timestamp (nullable = true)\n",
            " |-- _c6: integer (nullable = true)\n",
            " |-- _c7: string (nullable = true)\n",
            " |-- _c8: string (nullable = true)\n",
            " |-- _c9: integer (nullable = true)\n",
            " |-- _c10: integer (nullable = true)\n",
            " |-- _c11: integer (nullable = true)\n",
            " |-- _c12: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbK_qvf3hs5v"
      },
      "source": [
        "#### b) Read the file and specify the schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1xnLchfhzD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99fbe842-45fe-4829-8f97-294efbb299ab"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "# We first create a list with each column header\n",
        "# Note: avoid spaces and non-ascii characters on column names\n",
        "header = ([\"nComs\", \"lastActivity\", \"userId\", \n",
        "            \"body\", \"score\", \"creationDate\", \"numViewed\", \"title\", \n",
        "            \"tags\", \"nAnswers\", \"acceptedAnswerId\", \"postType\", \"id\"])\n",
        "            \n",
        "# Define the schema for the elements of the table\n",
        "# StructType -> Defines a schema for the DF from a list of StructFields\n",
        "# StructField -> Defines the name and type of each column, and whether it is nullable or not (True field)\n",
        "dfSE_Schema = StructType([\n",
        "  StructField(header[0], IntegerType(), True),\n",
        "  StructField(header[1], TimestampType(), True),\n",
        "  StructField(header[2], LongType(), True),\n",
        "  StructField(header[3], StringType(), True),\n",
        "  StructField(header[4], IntegerType(), True),\n",
        "  StructField(header[5], TimestampType(), True),\n",
        "  StructField(header[6], IntegerType(), True),\n",
        "  StructField(header[7], StringType(), True),\n",
        "  StructField(header[8], StringType(), True),\n",
        "  StructField(header[9], IntegerType(), True),\n",
        "  StructField(header[10], LongType(), True),\n",
        "  StructField(header[11], ByteType(), True),\n",
        "  StructField(header[12], LongType(), True)\n",
        "  ])\n",
        "  \n",
        "dfSE = spark.read.format(\"csv\")\\\n",
        "                    .option(\"mode\", \"FAILFAST\")\\\n",
        "                    .option(\"sep\", \"~\")\\\n",
        "                    .option(\"inferSchema\", \"false\")\\\n",
        "                    .option(\"header\", \"false\")\\\n",
        "                    .option(\"nullValue\", \"null\")\\\n",
        "                    .option(\"compression\", \"bzip2\")\\\n",
        "                    .schema(dfSE_Schema)\\\n",
        "                    .load(os.environ[\"DRIVE_DATA\"] +\"italianPosts.csv.bz2\")\n",
        "dfSE.cache()                    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[nComs: int, lastActivity: timestamp, userId: bigint, body: string, score: int, creationDate: timestamp, numViewed: int, title: string, tags: string, nAnswers: int, acceptedAnswerId: bigint, postType: tinyint, id: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwS3ZIcFh3y2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191e2263-16c8-4ad6-a4c0-30025a5d47cd"
      },
      "source": [
        "dfSE.sort(\"id\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+---+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType| id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+---+\n",
            "|    2|2013-11-09 09:20:...|     8|&lt;p&gt;What is ...|   20|2013-11-05 20:22:...|      204|What are the rule...|&lt;word-choice&g...|       4|               2|       1|  1|\n",
            "|    9|2013-11-05 20:44:...|    17|&lt;p&gt;Translat...|   18|2013-11-05 20:36:...|     null|                null|                null|    null|            null|       2|  2|\n",
            "|    0|2013-11-05 20:37:...|     6|&lt;p&gt;[don't k...|    6|2013-11-05 20:37:...|     null|                null|                null|    null|            null|       2|  3|\n",
            "|    6|2013-11-07 17:27:...|    18|&lt;p&gt;Si sotto...|    4|2013-11-05 20:38:...|     null|                null|                null|    null|            null|       2|  4|\n",
            "|    5|2013-11-06 01:00:...|    18|&lt;p&gt;I am int...|   13|2013-11-05 20:46:...|      130|Tanto va la gatta...|    &lt;proverbs&gt;|       1|            null|       1|  5|\n",
            "|    0|2013-11-06 14:56:...|    18|&lt;p&gt;When an ...|   10|2013-11-05 21:01:...|      165|How do English wo...|     &lt;grammar&gt;|       4|               8|       1|  6|\n",
            "|    6|2013-11-05 21:09:...|     6|&lt;p&gt;While th...|   24|2013-11-05 21:09:...|     null|                null|                null|    null|            null|       2|  8|\n",
            "|    0|2013-11-06 10:25:...|    22|&lt;p&gt;Personal...|    6|2013-11-05 21:15:...|     null|                null|                null|    null|            null|       2|  9|\n",
            "|    2|2014-02-02 13:21:...|    17|&lt;p&gt;I often ...|   10|2013-11-05 21:29:...|      134|Is it correct to ...|&lt;foreign-words...|       3|              12|       1| 10|\n",
            "|    0|2014-07-26 19:17:...|    12|&lt;p&gt;What's t...|    6|2013-11-05 21:30:...|       92|'aver sceso le sc...|&lt;grammar&gt;&l...|       1|            null|       1| 11|\n",
            "|    4|2013-11-05 21:36:...|    22|&lt;p&gt;Grammati...|   19|2013-11-05 21:36:...|     null|                null|                null|    null|            null|       2| 12|\n",
            "|    2|2013-11-05 21:56:...|    15|&lt;p&gt;''avere'...|    7|2013-11-05 21:40:...|     null|                null|                null|    null|            null|       2| 13|\n",
            "|    0|2013-11-07 17:27:...|    10|&lt;p&gt;I wasn't...|    1|2013-11-05 21:52:...|     null|                null|                null|    null|            null|       2| 14|\n",
            "|    1|2014-03-07 12:47:...|    37|&lt;p&gt;Are ther...|   13|2013-11-05 21:57:...|      557|Are there rules f...|    &lt;pronouns&gt;|       1|              20|       1| 15|\n",
            "|    0|2014-02-02 13:21:...|     8|&lt;p&gt;It's not...|    6|2013-11-05 22:00:...|     null|                null|                null|    null|            null|       2| 16|\n",
            "|    1|2013-11-06 09:32:...|    12|&lt;p&gt;What is ...|    4|2013-11-05 22:17:...|       76|'apparire' vs. 's...| &lt;word-choice&gt;|       3|            null|       1| 17|\n",
            "|    0|2013-11-06 09:53:...|    12|&lt;p&gt;Which on...|    2|2013-11-05 22:34:...|       78|&quot;l'FBI&quot;...|&lt;articles&gt;&...|       2|            null|       1| 18|\n",
            "|    0|2013-11-06 09:33:...|    12|&lt;p&gt;How does...|    2|2013-11-05 22:38:...|       69|&quot;con 'degli'...| &lt;word-choice&gt;|       2|              25|       1| 19|\n",
            "|    0|2013-11-05 23:07:...|     8|&lt;p&gt;From the...|   12|2013-11-05 22:42:...|     null|                null|                null|    null|            null|       2| 20|\n",
            "|    2|2013-11-05 22:47:...|    41|&lt;p&gt;IMO ther...|    2|2013-11-05 22:47:...|     null|                null|                null|    null|            null|       2| 21|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1wlNqCsh4Wv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c241ece0-34c7-4403-d076-81cedde372a1"
      },
      "source": [
        "dfSE.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nComs: integer (nullable = true)\n",
            " |-- lastActivity: timestamp (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- score: integer (nullable = true)\n",
            " |-- creationDate: timestamp (nullable = true)\n",
            " |-- numViewed: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- nAnswers: integer (nullable = true)\n",
            " |-- acceptedAnswerId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JqL8PojOEa"
      },
      "source": [
        "## Basic operations with DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx69XYmUjUP7"
      },
      "source": [
        "### Show rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRtkoWUZjaHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3432fc08-e54f-49ca-df87-59c03de2a344"
      },
      "source": [
        "# show(n) shows the first n rows (by default, n=20)\n",
        "dfSE.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     null|                null|                null|    null|            null|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            null|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     null|                null|                null|    null|            null|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     null|                null|                null|    null|            null|       2|1169|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Nyk4RrjePd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156ea7e8-a982-4f76-cc90-890b16a0e948"
      },
      "source": [
        "# Say that we do not want to truncate the long fields\n",
        "dfSE.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------+---------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+--------+----------------+--------+----+\n",
            "|nComs|lastActivity           |userId|body                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |score|creationDate           |numViewed|title                                                                                                 |tags                                                               |nAnswers|acceptedAnswerId|postType|id  |\n",
            "+-----+-----------------------+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------+---------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+--------+----------------+--------+----+\n",
            "|4    |2013-11-11 18:21:10.903|17    |&lt;p&gt;The infinitive tense is commonly used for expressing rules especially in signs (of any kind, not just road signs).&lt;/p&gt;&lt;p&gt;For instance&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Non fumare&lt;br&gt;  Non calpestare il prato&lt;br&gt;  Tenere la destra&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;The language &quot;trick&quot; behind this use of the infinitive form is the omission of the clause &lt;em&gt;Si prega di&lt;/em&gt; or equivalent, so the above sentences are read as&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;&lt;em&gt;&lt;strong&gt;Si prega di&lt;/em&gt;&lt;/strong&gt; non fumare&lt;br&gt;  &lt;strong&gt;&lt;em&gt;Si prega di&lt;/em&gt;&lt;/strong&gt; non calpestare il prato&lt;br&gt;  &lt;strong&gt;&lt;em&gt;Si prega di&lt;/em&gt;&lt;/strong&gt; tenere la destra&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Such form is not used in everyday's spoken language, as it's a convention used for giving orders and stating rules in an impersonal and formal way.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;That being said, there's an official use of the infinitive tense as imperative, which is the negative imperative.&lt;/p&gt;&lt;p&gt;In Italian the positive imperative form goes as follows&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Tieni la destra!&lt;br&gt;  Parla con lei!&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;whereas the negative imperative is formed with &lt;strong&gt;&lt;em&gt;non + infinitive tense&lt;/em&gt;&lt;/strong&gt;, as in &lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Non tenere la destra!&lt;br&gt;  Non parlare con lei!&lt;/p&gt;&lt;/blockquote&gt;&lt;hr&gt;&lt;p&gt;As discussed in the comments, it's also nice to notice the differences and the similarities with other Romance languages, such as Spanish and French.&lt;/p&gt;&lt;p&gt;Apparently French has the same identical construct as Italian for expressing formal impersonal orders, for instance&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Ne pas fumer&lt;br&gt;  &lt;em&gt;Non fumare&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;which is again a shortening for&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Merci de ne pas fumer&lt;br&gt;  &lt;em&gt;Grazie di non fumare&lt;/em&gt; or more idiomatically &lt;em&gt;Si prega di non fumare&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;On the other hand Spanish behaves differently and it doesn't have a special construct for impersonal orders, rather just using the formal imperative form, which is formed with the subjunctive&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;No fume&lt;br&gt;  &lt;em&gt;Non fumare&lt;/em&gt;, but also &lt;em&gt;Non fumi&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;or&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Reduzca la velocidad&lt;br&gt;  &lt;em&gt;Ridurre la velocità&lt;/em&gt;, but also &lt;em&gt;Riduca la velocità&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;|23   |2013-11-10 19:37:54.187|null     |null                                                                                                  |null                                                               |null    |null            |2       |1165|\n",
            "|5    |2013-11-10 20:31:00.177|12    |&lt;p&gt;Come credo sia conosciuto da tutti quelli che usano viaggiare con l'automobile, molti italiani hanno uno strano rapporto con gli abbaglianti; alcuni li amano così tanto che preferiscono mantenerli sempre accesi, altri invece li usano per segnalare, se non addirittura per comunicare informazioni di vario genere, dalla presenza di autovelox alla protesta per presunte violazioni del codice della strada.&lt;/p&gt;&lt;p&gt;Al di lá delle considerazioni e dei commenti circa queste abitudini, mi piacerebbe sapere se il verbo &quot;sfanagliare&quot; è normalmente usato, e compreso, in tutte le regioni italiane o se, magari, ci sono altri verbi in uso, purchè simpatici come quello.&lt;/p&gt;&lt;p&gt;Laddove qualcuno non avesse compreso l'uso del aforementioned verbo, ecco un esempio:&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;&quot;Ehi!&quot; - dice il marito a sua moglie - &quot;Quello li mi sta sfanagliando, st***o!&quot;&lt;/p&gt;    &lt;p&gt;E la moglie, &quot;Caro, rallenta; magari più avanti c'è un autovelox, cribbio!&quot;&lt;/p&gt;&lt;/blockquote&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |1    |2013-11-10 19:44:53.797|61       |Cosa sapreste dirmi della diffusione del verbo &quot;sfanagliare&quot; nelle diverse regioni italiane?|&lt;word-choice&gt;                                                |1       |null            |1       |1166|\n",
            "|2    |2013-11-10 20:31:00.177|17    |&lt;p&gt;Il verbo &lt;strong&gt;&lt;em&gt;sfanagliare&lt;/em&gt;&lt;/strong&gt; è un verbo inventato, non esistente nella lingua italiana, ma questo penso fosse chiaro dalla domanda.&lt;/p&gt;&lt;p&gt;Personalmente non l'ho mai sentito usare nel nord Italia, quindi non credo abbia una diffusione regionale omogenea. Un'alternativa che mi è capitato invece di sentire  è &lt;strong&gt;&lt;em&gt;sfanalare&lt;/em&gt;&lt;/strong&gt;, con significato identico.&lt;/p&gt;&lt;p&gt;Ad ogni modo, non sono sicuro dell'interpretazione di &lt;strong&gt;&lt;em&gt;sfanalare&lt;/em&gt;&lt;/strong&gt;/&lt;em&gt;&lt;strong&gt;sfanagliare&lt;/em&gt;&lt;/strong&gt; con il significato di &lt;strong&gt;&lt;em&gt;accecare con gli abbaglianti&lt;/em&gt;&lt;/strong&gt;. Probabilmente il significato che gli attribuirei è lo stesso di &lt;strong&gt;&lt;em&gt;fare i fari&lt;/em&gt;&lt;/strong&gt;, ossia &lt;strong&gt;&lt;em&gt;segnalare qualcosa tramite i fari abbaglianti&lt;/em&gt;&lt;/strong&gt;, solitamente accendendoli e spegnedoli ripetutamente. Per esempio&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Non mi ero accorto che il semaforo fosse diventato verde e il tizio dietro mi ha fatto i fari&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;(ok l'esempio è un po' tirato, sappiamo benissimo che il tizio di turno normalmente suona il clacson e tira una bestemmia...)&lt;/p&gt;&lt;p&gt;oppure&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Una vecchia consuetudine italiana era quella di sfanalare per segnalare la presenza della polizia stradale&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Nell'esempio che hai menzionato userei invece qualcosa del tipo&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Quello lì mi sta abbagliando (con sti c***o di fari, &lt;em&gt;ndt&lt;/em&gt;), st***o!&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;or&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Quello lì mi sta accecando (con sti c***o di fari, &lt;em&gt;ndt&lt;/em&gt;), st***o!&lt;/p&gt;&lt;/blockquote&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |5    |2013-11-10 19:58:02.1  |null     |null                                                                                                  |null                                                               |null    |null            |2       |1167|\n",
            "|1    |2014-07-25 13:15:02.27 |154   |&lt;p&gt;As part of my masters in linguistics, I am taking a course on the subject of irony. We were given examples of sentences that are most likely ironic, as the English sentence &quot;he is not exceptionally smart&quot; (which has the structure &quot;he is not exceptionally X&quot;). This does not mean literally that he is smart at an exceptional level, but rather, ironically, that he is very stupid.&lt;/p&gt;&lt;p&gt;Are there similar constructions in Italian, preferably ones that involve superlative and negation?&lt;/p&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |11   |2013-11-10 22:03:41.027|187      |Ironic constructions in Italian                                                                       |&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|4       |1170            |1       |1168|\n",
            "|0    |2013-11-10 22:15:17.693|70    |&lt;p&gt;&lt;em&gt;Non è furbissimo&lt;/em&gt; can be used in the same sense as your example; or &lt;em&gt;non è velocissimo&lt;/em&gt; for someone who's rather slow. Maybe adding &lt;em&gt;proprio&lt;/em&gt;: &lt;em&gt;non è proprio furbissimo&lt;/em&gt;, which is more explicit in denying the smartness of the person.&lt;/p&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |3    |2013-11-10 22:15:17.693|null     |null                                                                                                  |null                                                               |null    |null            |2       |1169|\n",
            "+-----+-----------------------+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------+---------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1BBaaz-jgp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18afe371-c42a-4c5b-f788-5902d32ebc6a"
      },
      "source": [
        "# take(n) returns the first n rows as a Python list of Row objects\n",
        "list = dfSE.take(5)\n",
        "print(list[1])\n",
        "print(\"\\n\")\n",
        "# collect() returns the DataFrame as a Python list of Row objects\n",
        "# Warning: if the DataFrame is too large, it might collapse the Driver!\n",
        "list2 = dfSE.collect()\n",
        "print(list2[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(nComs=5, lastActivity=datetime.datetime(2013, 11, 10, 20, 31, 0, 177000), userId=12, body=\"&lt;p&gt;Come credo sia conosciuto da tutti quelli che usano viaggiare con l'automobile, molti italiani hanno uno strano rapporto con gli abbaglianti; alcuni li amano così tanto che preferiscono mantenerli sempre accesi, altri invece li usano per segnalare, se non addirittura per comunicare informazioni di vario genere, dalla presenza di autovelox alla protesta per presunte violazioni del codice della strada.&lt;/p&gt;&lt;p&gt;Al di lá delle considerazioni e dei commenti circa queste abitudini, mi piacerebbe sapere se il verbo &quot;sfanagliare&quot; è normalmente usato, e compreso, in tutte le regioni italiane o se, magari, ci sono altri verbi in uso, purchè simpatici come quello.&lt;/p&gt;&lt;p&gt;Laddove qualcuno non avesse compreso l'uso del aforementioned verbo, ecco un esempio:&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;&quot;Ehi!&quot; - dice il marito a sua moglie - &quot;Quello li mi sta sfanagliando, st***o!&quot;&lt;/p&gt;    &lt;p&gt;E la moglie, &quot;Caro, rallenta; magari più avanti c'è un autovelox, cribbio!&quot;&lt;/p&gt;&lt;/blockquote&gt;\", score=1, creationDate=datetime.datetime(2013, 11, 10, 19, 44, 53, 797000), numViewed=61, title='Cosa sapreste dirmi della diffusione del verbo &quot;sfanagliare&quot; nelle diverse regioni italiane?', tags='&lt;word-choice&gt;', nAnswers=1, acceptedAnswerId=None, postType=1, id=1166)\n",
            "\n",
            "\n",
            "Row(nComs=1, lastActivity=datetime.datetime(2014, 1, 16, 19, 56, 5, 933000), userId=63, body='&lt;p&gt;Suppose I want to translate an English sentence like &quot;I have walked in the park for a year.&quot; The first though I had was translating the sentence as follows.&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Ho camminato nel parco per un anno.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;It seems correct, except for the fact that Present Perfect is used to talk about a past event that is still relevant for the present. That means the sentence I used as example would be understood as saying that I am still walking in the park. Similarly, &quot;I have gone to that store since I was a teenager.&quot; would mean I am still going to that store.&lt;br&gt;That is not the meaning of &quot;ho camminato nel parco per un anno&quot; which means I am not walking anymore in the park.&lt;/p&gt;&lt;p&gt;I thought of using the Simple Past, but I am not sure how to use it with a time reference. Apart that, &lt;em&gt;camminavo nel parco&lt;/em&gt; still means I am not anymore walking.&lt;/p&gt;&lt;p&gt;How should I translate the Present Perfect used in English?&lt;/p&gt;', score=4, creationDate=datetime.datetime(2013, 11, 11, 11, 31, 2, 343000), numViewed=114, title='How should I translate the Present Perfect used in English?', tags='&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;', nAnswers=2, acceptedAnswerId=1177, postType=1, id=1175)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPDx7xvIjif4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd516b8-d2bd-44ff-8b92-e7665863694b"
      },
      "source": [
        "import os\n",
        "# sample(withReplacement, fraction, seed=None) returns a new Dataframe with a fraction of the original rows\n",
        "dfSESampled = dfSE.sample(False, 0.1, seed=None)\n",
        "print(\"Original Number of rows = {0}; Number of sampled rows = {1}\".format(dfSE.count(), dfSESampled.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Number of rows = 1261; Number of sampled rows = 130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-DOlABOjkc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc8f774-b1d3-45f4-a798-d2cb4d30fd95"
      },
      "source": [
        "# limit(n) limits the number of rows calculated to n\n",
        "dfSE_10rows = dfSE.sample(False, 0.1, seed=None).limit(10)\n",
        "print(\"Number of sampled rows = {0}\".format(dfSE_10rows.count()))\n",
        "dfSE_10rows.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sampled rows = 10\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            null|       1|1166|\n",
            "|    0|2013-11-11 18:20:...|   132|&lt;p&gt;I would ...|    8|2013-11-11 14:04:...|     null|                null|                null|    null|            null|       2|1181|\n",
            "|    2|2013-11-27 18:42:...|   124|&lt;p&gt;L'espres...|   12|2013-11-12 12:25:...|     null|                null|                null|    null|            null|       2|1214|\n",
            "|    0|2013-11-12 12:53:...|    63|&lt;p&gt;Lo Zinga...|    6|2013-11-12 12:53:...|     null|                null|                null|    null|            null|       2|1216|\n",
            "|    6|2014-04-09 18:02:...|    63|&lt;p&gt;In Lomba...|    5|2013-11-12 13:12:...|      100|Is &quot;essere d...|&lt;usage&gt;&lt;...|       4|            1226|       1|1218|\n",
            "|    0|2013-11-12 13:27:...|    63|&lt;p&gt;&quot;Pe...|    1|2013-11-12 13:27:...|     null|                null|                null|    null|            null|       2|1220|\n",
            "|    0|2013-11-12 18:53:...|    87|&lt;p&gt;Present ...|    5|2013-11-12 18:53:...|     null|                null|                null|    null|            null|       2|1237|\n",
            "|    1|2013-11-12 22:13:...|    37|&lt;p&gt;b. perch...|   12|2013-11-12 22:13:...|     null|                null|                null|    null|            null|       2|1245|\n",
            "|    1|2013-11-15 17:12:...|    70|&lt;p&gt;&lt;em&g...|    6|2013-11-15 17:12:...|     null|                null|                null|    null|            null|       2|1277|\n",
            "|    0|2013-11-16 09:46:...|     5|&lt;p&gt;Si tratt...|   14|2013-11-16 09:46:...|     null|                null|                null|    null|            null|       2|1280|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HXAspRdjnV-"
      },
      "source": [
        "### Execute an operation on each row\n",
        "The method `foreach` applies a function to each row\n",
        "\n",
        "- The DataFrame is not modified and no other DataFrames are created\n",
        "- `foreach` is executed in the Workers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QC31oFjvjx"
      },
      "source": [
        "def printid(f):\n",
        "    print(f[\"id\"])\n",
        "    \n",
        "# In theory, this code should print all values of the 'id' column.\n",
        "# Due to the way the notebook manages tasks, it is not possible to see any output.\n",
        "# Run it on a pyspark-shell to see the output.\n",
        "dfSE_10rows.foreach(printid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTZ2CtybjwQn"
      },
      "source": [
        "### Select columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQamd1S0jznG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cf628c-0cdb-421e-8aa2-beafe0a3cc72"
      },
      "source": [
        "# Creates a new DataFrame by selecting columns by name\n",
        "dfIdBody = dfSE.select(\"id\", \"body\")\n",
        "dfIdBody.show(5)\n",
        "\n",
        "print(\"The idBody object is of type {0}\".format(type(dfIdBody)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|  id|                body|\n",
            "+----+--------------------+\n",
            "|1165|&lt;p&gt;The infi...|\n",
            "|1166|&lt;p&gt;Come cre...|\n",
            "|1167|&lt;p&gt;Il verbo...|\n",
            "|1168|&lt;p&gt;As part ...|\n",
            "|1169|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "The idBody object is of type <class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlZy8j4j2sR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a940dc5d-5307-4441-b189-18a7182f40f7"
      },
      "source": [
        "# Another way of specifying the columns to select\n",
        "dfIdBody2 = dfSE.select(dfSE.id, dfSE.body)\n",
        "dfIdBody2.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|  id|                body|\n",
            "+----+--------------------+\n",
            "|1165|&lt;p&gt;The infi...|\n",
            "|1166|&lt;p&gt;Come cre...|\n",
            "|1167|&lt;p&gt;Il verbo...|\n",
            "|1168|&lt;p&gt;As part ...|\n",
            "|1169|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQWu1PaXj3aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bbe3a8-9a44-478d-cb42-c65fd5aea068"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "colId = col(\"id\")\n",
        "colCreateDate = col(\"creationDate\")\n",
        "print(\"The colId object is of type {0}\".format(type(colId)))\n",
        "print(\"The colCreateDate object is of type {0}\".format(type(colCreateDate)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The colId object is of type <class 'pyspark.sql.column.Column'>\n",
            "The colCreateDate object is of type <class 'pyspark.sql.column.Column'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SvgG2Sjj5BW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2874a3-56e9-47eb-fb8b-5287c047985d"
      },
      "source": [
        "# ... and create a DataFrame from Column objects, by renaming the columns\n",
        "dfIdBodyDate = dfSE.select(colId, \n",
        "                              colCreateDate.alias(\"Creation_date\"), \n",
        "                              dfSE.body.alias(\"Content\"))\n",
        "dfIdBodyDate.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+--------------------+\n",
            "|  id|       Creation_date|             Content|\n",
            "+----+--------------------+--------------------+\n",
            "|1165|2013-11-10 19:37:...|&lt;p&gt;The infi...|\n",
            "|1166|2013-11-10 19:44:...|&lt;p&gt;Come cre...|\n",
            "|1167|2013-11-10 19:58:...|&lt;p&gt;Il verbo...|\n",
            "|1168|2013-11-10 22:03:...|&lt;p&gt;As part ...|\n",
            "|1169|2013-11-10 22:15:...|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw45U9EYj9Nh"
      },
      "source": [
        "#### Select columns by using expressions\n",
        "\n",
        "To select columns using SQL expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSTG7pXokAd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7f85c1-c05c-4e2c-ddd6-1e59cc898ef1"
      },
      "source": [
        "from pyspark.sql.functions import expr\n",
        "# Same DataFrame as before but using expressions\n",
        "dfIdDateBodyExpr = dfSE.select(\n",
        "                           expr(\"id AS ID\"), \n",
        "                           expr('creationDate AS Creation_date'), \n",
        "                           expr(\"body AS Content\"))\n",
        "dfIdDateBodyExpr.show(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+--------------------+\n",
            "|  ID|       Creation_date|             Content|\n",
            "+----+--------------------+--------------------+\n",
            "|1165|2013-11-10 19:37:...|&lt;p&gt;The infi...|\n",
            "|1166|2013-11-10 19:44:...|&lt;p&gt;Come cre...|\n",
            "|1167|2013-11-10 19:58:...|&lt;p&gt;Il verbo...|\n",
            "|1168|2013-11-10 22:03:...|&lt;p&gt;As part ...|\n",
            "|1169|2013-11-10 22:15:...|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO43v_chkCg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe81ce9-ee6c-4f09-fc38-c9366053d8c9"
      },
      "source": [
        "# We can use more complex expressions\n",
        "dfSE.selectExpr(\"*\", # Select all columns and set ValidReply to True for those with, at least, one reply.\n",
        "                \"(nAnswers IS NOT NULL) as ValidReply\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----------+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|ValidReply|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----------+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     null|                null|                null|    null|            null|       2|1165|     false|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            null|       1|1166|      true|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     null|                null|                null|    null|            null|       2|1167|     false|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|      true|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     null|                null|                null|    null|            null|       2|1169|     false|\n",
            "|    2|2013-11-10 22:17:...|    17|&lt;p&gt;There's ...|    8|2013-11-10 22:17:...|     null|                null|                null|    null|            null|       2|1170|     false|\n",
            "|    1|2013-11-11 09:51:...|    63|&lt;p&gt;As other...|    3|2013-11-11 09:51:...|     null|                null|                null|    null|            null|       2|1171|     false|\n",
            "|    1|2013-11-12 23:57:...|    63|&lt;p&gt;The expr...|    1|2013-11-11 10:09:...|     null|                null|                null|    null|            null|       2|1172|     false|\n",
            "|    9|2014-01-05 11:13:...|    63|&lt;p&gt;When I w...|    5|2013-11-11 10:28:...|      122|Is &quot;scancell...|&lt;usage&gt;&lt;...|       3|            1181|       1|1173|      true|\n",
            "|    0|2013-11-11 10:58:...|    18|&lt;p&gt;Wow, wha...|    5|2013-11-11 10:58:...|     null|                null|                null|    null|            null|       2|1174|     false|\n",
            "|    1|2014-01-16 19:56:...|    63|&lt;p&gt;Suppose ...|    4|2013-11-11 11:31:...|      114|How should I tran...|&lt;usage&gt;&lt;...|       2|            1177|       1|1175|      true|\n",
            "|    0|2013-11-11 14:36:...|    63|&lt;p&gt;Except w...|    3|2013-11-11 11:39:...|       58|Using a comma bet...|&lt;usage&gt;&lt;...|       2|            1182|       1|1176|      true|\n",
            "|    3|2014-01-16 19:56:...|    71|&lt;p&gt;Both you...|    6|2013-11-11 11:57:...|     null|                null|                null|    null|            null|       2|1177|     false|\n",
            "|    0|2013-11-11 12:00:...|    12|&lt;blockquote&gt...|    1|2013-11-11 12:00:...|     null|                null|                null|    null|            null|       2|1178|     false|\n",
            "|    0|2013-11-12 11:24:...|    63|&lt;p&gt;Comparin...|    3|2013-11-11 12:58:...|       60|Using the conditi...|&lt;usage&gt;&lt;...|       2|            1180|       1|1179|      true|\n",
            "|    4|2013-11-11 19:54:...|    18|&lt;p&gt;Using th...|    5|2013-11-11 13:48:...|     null|                null|                null|    null|            null|       2|1180|     false|\n",
            "|    0|2013-11-11 18:20:...|   132|&lt;p&gt;I would ...|    8|2013-11-11 14:04:...|     null|                null|                null|    null|            null|       2|1181|     false|\n",
            "|    1|2013-11-11 14:36:...|   132|&lt;p&gt;Putting ...|   11|2013-11-11 14:17:...|     null|                null|                null|    null|            null|       2|1182|     false|\n",
            "|    2|2013-11-14 09:56:...|    22|&lt;p&gt;Many peo...|    6|2013-11-11 14:43:...|      321|Can Dante Alighie...|&lt;history&gt;&l...|       1|            1263|       1|1183|      true|\n",
            "|    2|2013-11-11 23:23:...|   159|&lt;p&gt;Sono un'...|    7|2013-11-11 18:19:...|      138|origine dell'espr...|&lt;idioms&gt;&lt...|       2|            1185|       1|1184|      true|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3fIFG0MkHY0"
      },
      "source": [
        "### Rename, add and delete columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4-CC8StkJ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752c4afa-89d8-4169-e07d-3eac75606bf9"
      },
      "source": [
        "# Rename the creationDate column\n",
        "dfSE = dfSE.withColumnRenamed(\"creationDate\", \"Creation_date\")\n",
        "dfSE.cache()\n",
        "dfSE.select(\"Creation_date\", \n",
        "            dfSE.numViewed.alias(\"Number_of_visits\"), \n",
        "            \"score\", \n",
        "            \"postType\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+----------------+-----+--------+\n",
            "|Creation_date          |Number_of_visits|score|postType|\n",
            "+-----------------------+----------------+-----+--------+\n",
            "|2013-11-10 19:37:54.187|null            |23   |2       |\n",
            "|2013-11-10 19:44:53.797|61              |1    |1       |\n",
            "|2013-11-10 19:58:02.1  |null            |5    |2       |\n",
            "|2013-11-10 22:03:41.027|187             |11   |1       |\n",
            "|2013-11-10 22:15:17.693|null            |3    |2       |\n",
            "|2013-11-10 22:17:22.38 |null            |8    |2       |\n",
            "|2013-11-11 09:51:11.22 |null            |3    |2       |\n",
            "|2013-11-11 10:09:05.117|null            |1    |2       |\n",
            "|2013-11-11 10:28:12.613|122             |5    |1       |\n",
            "|2013-11-11 10:58:02.62 |null            |5    |2       |\n",
            "|2013-11-11 11:31:02.343|114             |4    |1       |\n",
            "|2013-11-11 11:39:12.703|58              |3    |1       |\n",
            "|2013-11-11 11:57:03.723|null            |6    |2       |\n",
            "|2013-11-11 12:00:25.583|null            |1    |2       |\n",
            "|2013-11-11 12:58:38.137|60              |3    |1       |\n",
            "|2013-11-11 13:48:24.287|null            |5    |2       |\n",
            "|2013-11-11 14:04:00.753|null            |8    |2       |\n",
            "|2013-11-11 14:17:44.79 |null            |11   |2       |\n",
            "|2013-11-11 14:43:47.487|321             |6    |1       |\n",
            "|2013-11-11 18:19:12.253|138             |7    |1       |\n",
            "+-----------------------+----------------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFWWZ4askPrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cb433c-6964-4f20-dd63-40afe1f011e7"
      },
      "source": [
        "# Add a new column 'ones' with all its values set to 1\n",
        "from pyspark.sql.functions import lit\n",
        "# lit transforms a literal in Python to Spark internal format\n",
        "# (in this example, IntegerType)\n",
        "dfSE = dfSE.withColumn(\"ones\", lit(1))\n",
        "dfSE.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|ones|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     null|                null|                null|    null|            null|       2|1165|   1|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            null|       1|1166|   1|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     null|                null|                null|    null|            null|       2|1167|   1|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|   1|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     null|                null|                null|    null|            null|       2|1169|   1|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wWzrupfkRth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f644a164-fee5-4d2f-aad0-e2bb0340876b"
      },
      "source": [
        "# Removes a column using drop\n",
        "dfSE = dfSE.drop(col(\"ones\"))\n",
        "dfSE.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nComs',\n",
              " 'lastActivity',\n",
              " 'userId',\n",
              " 'body',\n",
              " 'score',\n",
              " 'Creation_date',\n",
              " 'numViewed',\n",
              " 'title',\n",
              " 'tags',\n",
              " 'nAnswers',\n",
              " 'acceptedAnswerId',\n",
              " 'postType',\n",
              " 'id']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsxTogrdkWt0"
      },
      "source": [
        "### Delete null and duplicated values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XT8uw47kY2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b8d7d5-cd15-4eb2-a0c1-ebd967c577ea"
      },
      "source": [
        "# Remove all rows that have null on any of their columns\n",
        "dfNoNulls = dfSE.dropna(\"any\")\n",
        "print(\"Initial number or rows: {0}; number of non null rows: {1}\"\n",
        "       .format(dfSE.count(), dfNoNulls.count()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number or rows: 1261; number of non null rows: 222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0xh2BW5ka_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcccbb27-6d4a-4f14-b5e2-e237938c4443"
      },
      "source": [
        "# Remove rows that have null on all their columns\n",
        "dfNeitherNull = dfSE.dropna(\"all\")\n",
        "print(\"Number of rows with all columns set to null: {0}\"\n",
        "       .format(dfSE.count() - dfNeitherNull.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with all columns set to null: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYKhJBTQkdbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09384b0c-eb15-412c-aae2-0618b71c079b"
      },
      "source": [
        "# Remove duplicated rows\n",
        "dfWithoutDuplicates = dfSE.dropDuplicates()\n",
        "print(\"Number of duplicated rows: {0}\"\n",
        "       .format(dfSE.count() - dfWithoutDuplicates.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicated rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fgz5rXhkf-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69ec188-da85-499c-c517-49ad4580856b"
      },
      "source": [
        "# Remove rows when a given column is duplicated\n",
        "dfWithoutDuplicatedUser = dfSE.dropDuplicates([\"userId\"])\n",
        "print(\"Number of unique users: {0}\"\n",
        "       .format(dfWithoutDuplicatedUser.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique users: 218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8CSyfr1kjWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a158bf-4829-46a5-ca10-885614bddd12"
      },
      "source": [
        "# Other examples\n",
        "dfNoNullnumViewedAcceptedAnswerId = dfSE.dropna(\"any\", subset=[\"numViewed\", \"acceptedAnswerId\"])\n",
        "print(\"Number of rows with numViewed AND acceptedAnswerId not null: {0}\"\n",
        "       .format(dfNoNullnumViewedAcceptedAnswerId.count()))\n",
        "\n",
        "dfNoNullnumViewedAcceptedAnswerId = dfSE.dropna(\"all\", subset=[\"numViewed\", \"acceptedAnswerId\"])\n",
        "print(\"Number of rows with numViewed OR acceptedAnswerId not null: {0}\"\n",
        "       .format(dfNoNullnumViewedAcceptedAnswerId.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with numViewed AND acceptedAnswerId not null: 222\n",
            "Number of rows with numViewed OR acceptedAnswerId not null: 374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR8rAZGCkln-"
      },
      "source": [
        "### Replacing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGtTf0FmkuXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ecccc1-1fc9-473c-ed2d-cdd54d70cd26"
      },
      "source": [
        "# Replace with '0' all null values in the numVistas and nAnswers fields\n",
        "dfSE = dfSE.fillna(0, subset=[\"numViewed\", \"nAnswers\"])\n",
        "dfSE.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|        0|                null|                null|       0|            null|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            null|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|        0|                null|                null|       0|            null|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|        0|                null|                null|       0|            null|       2|1169|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZkZtlAkwd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8e6317-e271-49c2-b3f2-a55cde144b82"
      },
      "source": [
        "# Replace the value 1170 with 3000 in columns \"id\" and \"acceptedAnswerId\"\n",
        "dfSE.select(\"id\", \"acceptedAnswerId\").show(10)\n",
        "dfSE.replace(1170, 3000, subset=[\"id\", \"acceptedAnswerId\"])\\\n",
        "    .select(\"id\", \"acceptedAnswerId\")\\\n",
        "    .show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------------+\n",
            "|  id|acceptedAnswerId|\n",
            "+----+----------------+\n",
            "|1165|            null|\n",
            "|1166|            null|\n",
            "|1167|            null|\n",
            "|1168|            1170|\n",
            "|1169|            null|\n",
            "|1170|            null|\n",
            "|1171|            null|\n",
            "|1172|            null|\n",
            "|1173|            1181|\n",
            "|1174|            null|\n",
            "+----+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+----+----------------+\n",
            "|  id|acceptedAnswerId|\n",
            "+----+----------------+\n",
            "|1165|            null|\n",
            "|1166|            null|\n",
            "|1167|            null|\n",
            "|1168|            3000|\n",
            "|1169|            null|\n",
            "|3000|            null|\n",
            "|1171|            null|\n",
            "|1172|            null|\n",
            "|1173|            1181|\n",
            "|1174|            null|\n",
            "+----+----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0AhRhpzky7X"
      },
      "source": [
        "## Saving DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVR4GjW2k2S6"
      },
      "source": [
        "As for reading, Spark can save DateFrames in multiple formats:\n",
        "\n",
        "- CSV, JSON, Parquet, Hadoop...\n",
        "\n",
        "It can write them as well on a database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY8vG9xbk78E"
      },
      "source": [
        "# Save the dfSE DataFrame in JSON format\n",
        "#dfSE.write.format(\"json\").mode(\"overwrite\").save(\"/content/dfSE.json\")\n",
        "dfSE.write.json(os.environ[\"DRIVE_DATA\"] + \"dfSE.json\",mode=\"overwrite\")\n",
        "\n",
        "#!mv /content/dfSE.json \"$DRIVE_DATA\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZdDPlv1lGzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5039248e-1edf-44d3-c377-763fb75d0d8b"
      },
      "source": [
        "!ls -alh \"$DRIVE_DATA\"/dfSE.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.4M\n",
            "-rw------- 1 root root 1.4M Nov 17 13:49 part-00000-d3cf9218-5d2b-47a7-9d4c-ad26aea1c5c8-c000.json\n",
            "-rw------- 1 root root  11K Nov 17 13:49 .part-00000-d3cf9218-5d2b-47a7-9d4c-ad26aea1c5c8-c000.json.crc\n",
            "-rw------- 1 root root    0 Nov 17 13:49 _SUCCESS\n",
            "-rw------- 1 root root    8 Nov 17 13:49 ._SUCCESS.crc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Q-63hElJYQ"
      },
      "source": [
        "# Save the DataFrame using Parquet\n",
        "dfSE.write.format(\"parquet\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .save(os.environ[\"DRIVE_DATA\"] + \"dfSE.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp6xMAnLlMJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165b29ec-6165-43d8-c4a3-e4e7093f68cf"
      },
      "source": [
        "# Parquet uses by default the Snappy compressed format\n",
        "!ls -alh \"$DRIVE_DATA\"/dfSE.parquet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 620K\n",
            "-rw------- 1 root root 615K Nov 17 13:49 part-00000-d7921be5-439d-4e88-a626-88d88582c493-c000.snappy.parquet\n",
            "-rw------- 1 root root 4.9K Nov 17 13:49 .part-00000-d7921be5-439d-4e88-a626-88d88582c493-c000.snappy.parquet.crc\n",
            "-rw------- 1 root root    0 Nov 17 13:49 _SUCCESS\n",
            "-rw------- 1 root root    8 Nov 17 13:49 ._SUCCESS.crc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPpyVB30lPd-"
      },
      "source": [
        "It will create as many files as there are partitions in the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUTF4Q8QlRhI"
      },
      "source": [
        "dfSE2 = dfSE.repartition(2)\n",
        "# Save the DataFrame using Parquet, with gzip compression\n",
        "dfSE2.write.format(\"parquet\")\\\n",
        "     .mode(\"overwrite\")\\\n",
        "     .option(\"compression\", \"gzip\")\\\n",
        "     .save(os.environ[\"DRIVE_DATA\"] + \"/dfSE2.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuypMiRilTaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c33ad5e-ac0a-4c4a-bbc6-7b1f82b7c372"
      },
      "source": [
        "!ls -alh \"$DRIVE_DATA\"/dfSE2.parquet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 419K\n",
            "-rw------- 1 root root 203K Nov 17 13:49 part-00000-7bd533cd-5ac7-4d93-8702-abfc4ef90a7e-c000.gz.parquet\n",
            "-rw------- 1 root root 1.6K Nov 17 13:49 .part-00000-7bd533cd-5ac7-4d93-8702-abfc4ef90a7e-c000.gz.parquet.crc\n",
            "-rw------- 1 root root 212K Nov 17 13:49 part-00001-7bd533cd-5ac7-4d93-8702-abfc4ef90a7e-c000.gz.parquet\n",
            "-rw------- 1 root root 1.7K Nov 17 13:49 .part-00001-7bd533cd-5ac7-4d93-8702-abfc4ef90a7e-c000.gz.parquet.crc\n",
            "-rw------- 1 root root    0 Nov 17 13:49 _SUCCESS\n",
            "-rw------- 1 root root    8 Nov 17 13:49 ._SUCCESS.crc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQmqkp1lbU9"
      },
      "source": [
        "### Partitioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2YPJVuWlfTB"
      },
      "source": [
        "Spark can partition and save a file using the value of a given column\n",
        "\n",
        "- A directory is created for each different value in the partitioning column\n",
        "    - All data associated to that value are stored in that directory\n",
        "- It simplifies the access to the values associated to a given key\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMXPmB-6lii6"
      },
      "source": [
        "# Save our DataFrame partitioned by the userID field (using Parquet)\n",
        "dfSE.write.format(\"parquet\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .partitionBy(\"userId\")\\\n",
        "    .save(os.environ[\"DRIVE_DATA\"] + \"dfSE-partition.parquet\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HOlEv6olkyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d306b812-02d2-4739-d1d6-4c2f41f8cda0"
      },
      "source": [
        "#!ls -lh \"$DRIVE_DATA\"dfSE-partition.parquet\n",
        "!ls -lh \"$DRIVE_DATA\"dfSE-partition.parquet/userId=10\n",
        "#rm -rf \"$DRIVE_DATA\"dfSE-partition.parquet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.5K\n",
            "-rw------- 1 root root 4.4K Nov 17 13:49 part-00000-0254fd03-17bb-4f87-970a-e4abe084ab78.c000.snappy.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJSOev3XOPn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3ULPx4Y1LiR"
      },
      "source": [
        "## Exercise 3.1: Word count\n",
        "\n",
        "Count the number of words *per line* in the $DRIVE_DATA/quijote.txt file. \n",
        "\n",
        "Repeat the exercise but this time counting the number of words *in the whole file*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7Q_ljrX5RtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6851975f-9885-4a5e-ed6a-5510962de984"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "#dfQuijote.select(F.split(col('Value'), \" \")).show()\n",
        "df_line_word = dfQuijote.select(expr(\"SIZE(SPLIT(Value, ' '))\"))\n",
        "df_line_word.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|size(split(Value,  , -1))|\n",
            "+-------------------------+\n",
            "|                       12|\n",
            "|                        1|\n",
            "|                       14|\n",
            "|                       13|\n",
            "|                       11|\n",
            "|                        7|\n",
            "|                        1|\n",
            "|                        1|\n",
            "|                        3|\n",
            "|                        1|\n",
            "|                        5|\n",
            "|                        1|\n",
            "|                        7|\n",
            "|                        4|\n",
            "|                        1|\n",
            "|                        2|\n",
            "|                        1|\n",
            "|                        1|\n",
            "|                       10|\n",
            "|                        1|\n",
            "+-------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_line_word.agg({\"size(split(Value,  , -1))\":\"sum\"}).collect()[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC2rdc8R74HV",
        "outputId": "93e7063b-7db5-4026-a633-3c7d38a44eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "393764"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YKagWS58-58i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}